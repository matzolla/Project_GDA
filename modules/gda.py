# -*- coding: utf-8 -*-
"""GDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OqGKXMMApJFrCHToHKpjsvd7FAzzorq_
"""

"""
In the name of all the team, this file implements the Generative discriminant analysis
algorithm from scratch we build a class which compute all the parameters of the likelihood


Authors ---> NANCY
        ---> ORNELA
        ---> AVOTRA
        ---> FENOSOA
        ---> ALLASSAN
"""
import numpy as np
import pandas as pd


def calculate_phy(Y):
    """
    calculating the 1st parameters: phi=1{Y==1}/m
    input---> Y: np.array
    """
    m=len(Y)
    value= len(Y[Y==1.0])/m

    return value


def calculate_sigma(X,y,mu0,mu1):
    """comment it later!!!"""
    m=len(y)
    mu0 = mu0.reshape((1,X.shape[1]))
    mu1 = mu1.reshape((1,X.shape[1]))

    cov = np.zeros((X.shape[1],X.shape[1]))
    a = np.zeros(X.shape[1])
    for i in range(m):
        xi = X[i,:]
        # print(xi.shape)
        yi = y[i]
        if yi==1.0:
            sqr = (xi.reshape((1,X.shape[1])).T-mu1)@(xi.reshape((1,X.shape[1])).T-mu1).T
            cov = cov + sqr
        else:
            sqr=(xi.reshape((1,X.shape[1])).T-mu0)@(xi.reshape((1,X.shape[1])).T-mu0).T
            cov = cov + sqr

    return cov/m

def calculate_mu0_mu1(X,y):
    """comment it later!!!!"""
    m = len(y)
    y_pos = len(y[y==1.0])
    y_neg = len(y[y==0.0])

    sum_x_pos = np.zeros(X.shape[1])
    sum_x_neg = np.zeros(X.shape[1])

    for i in range(m):
        xi=X[i,:]
        yi=y[i]
        if yi==1.0:
            sum_x_pos = sum_x_pos + xi
            
        else:
          sum_x_neg = sum_x_neg + xi

    
    return  sum_x_neg/y_neg, sum_x_pos/y_pos #(1/m)*sum_x_neg/y_neg, (1/m)*sum_x_pos/y_pos?

df_frequency_encoding = pd.read_csv('df_frequency_encoding1.csv')
df_td_idf = pd.read_csv('df_td_idf1.csv')

df_frequency_encoding.head()

df_td_idf.head()

from sklearn import preprocessing
 
label_encoder = preprocessing.LabelEncoder()
 
df_frequency_encoding['label']= label_encoder.fit_transform(df_frequency_encoding['label'])

df_td_idf.isnull().sum().sum()

df_frequency_encoding.isnull().sum().sum()

"""### Function to perfom the dimenssion reduction by using PCA"""

from PCA import PCA

k = 2 # reduce the data dimensionality to 2
# X = df_frequency_encoding.iloc[:, :-1]
X = df_td_idf.iloc[:, :-1]
# X = X.fillna(0)
z = PCA(X, k)
principal_df = pd.DataFrame(z, columns=['PC1', 'PC2'])
principal_df.head()

# Visualize the result of PCA for 2 components
import matplotlib.pyplot as plt
import seaborn as sb
plt.figure(figsize = (6,6))
sb.scatterplot(data = principal_df , x = 'PC1',y = 'PC2')

"""### function to split a data"""

X = df_td_idf.iloc[:, :-1]
Y = df_td_idf.iloc[:,-1]
df = np.c_[principal_df,Y]
df = pd.DataFrame(df)
df

def split_data(df, train_percent= 0.8):
  np.random.seed(2)
  perm = np.random.permutation(df.index)

  n= len(df)
  train_index = int(train_percent * n)

  train = df.iloc[perm[:train_index]]
  test = df.iloc[perm[train_index:]]

  x_train, x_test, y_train, y_test= train.iloc[:, :-1], test.iloc[:, :-1], train.iloc[:, -1], test.iloc[:, -1]
  return x_train.values, x_test.values, y_train.values, y_test.values

x_train, x_test, y_train, y_test = split_data(df, train_percent= 0.8)
# x_train
# y_train

def predict(X,y,sigma,phi,mu0,mu1,m0=False,m1=False):
  preds = []
  for x in X:

    if m0:
      diff = x - mu0
      inv_sigma = np.linalg.inv(sigma)
      det_sigma = np.linalg.det(sigma)
      n = X.shape[0]
      px_py = (1/((np.pi)**(n/2)*np.sqrt(det_sigma)))* np.exp(-0.5* diff.T@inv_sigma@diff)
      post_0 = px_py * (1-phi)

    if m1:
      diff = x - mu1#.reshape((1,2))
      inv_sigma = np.linalg.inv(sigma)
      det_sigma = np.linalg.det(sigma)
      n = X.shape[0]
      px_py = (1/((np.pi)**(n/2)*np.sqrt(det_sigma)))* np.exp(-0.5* diff.T@inv_sigma@diff)
      post_1= px_py * phi

    classes = np.unique(y)
    ypred = classes[np.argmax([post_0, post_1])]
    preds.append(ypred)

  return post_0,post_1, preds

mu0,mu1 = calculate_mu0_mu1(x_train,y_train)
sigma = calculate_sigma(x_train,y_train,mu0,mu1)
phi = calculate_phy(y_train)

def accuracy(y_test,ypred):
  # out=0
  n=len(y_test)
  out = np.sum([1 if y_test[i]==ypred[i] else 0 for i in range(len(y_test))])
  return out/n

ypred = predict(x_test,y_test,sigma,phi,mu0,mu1,m0=True,m1=True)[2]
accuracy(y_test,ypred)
